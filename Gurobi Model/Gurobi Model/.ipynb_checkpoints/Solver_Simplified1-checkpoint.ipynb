{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import Model, GRB, quicksum, tuplelist\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following file works as a reference table to match the names of 2 sheets\n",
    "hub_list = pd.read_csv('Database/Hub list.csv')\n",
    "hub_list.Ref_City = hub_list.Ref_City + \"-\" + hub_list.Country\n",
    "\n",
    "# drop duplicates\n",
    "hub_list.drop_duplicates(subset = \"Ref_City\", keep='first', inplace=True)\n",
    "\n",
    "\n",
    "hub_ref = {}\n",
    "for row in hub_list.index:\n",
    "    hub_ref[hub_list.loc[row, \"City\"]] = hub_list.loc[row, \"Ref_City\"]\n",
    "\n",
    "    \n",
    "    \n",
    "def name_transform(city_name):\n",
    "    if city_name in hub_ref.keys():\n",
    "        return hub_ref[city_name]\n",
    "    else:\n",
    "        return city_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Version\n",
    "masterfile = pd.read_excel(\"Database/Simple/Simple Routes.xlsx\", sheet_name = 0)\n",
    "\n",
    "# Complete Version\n",
    "#masterfile = pd.read_csv(\"Database/inter_distances.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import forecast for creating the country set\n",
    "forecast = pd.read_csv(\"Database/Average_Forecast.csv\")\n",
    "forecast.fillna(0, inplace = True)\n",
    "\n",
    "# Only satisfied those the current network can reach\n",
    "# Otherwise the solution would be infeasible\n",
    "\n",
    "used_c = masterfile[\"Origin Country\"].unique().tolist() +  masterfile[\"Destination Country\"].unique().tolist() # Not every hubs in the hub list is used\n",
    "used_c = list( dict.fromkeys(used_c) )  # Remove duplicate\n",
    "\n",
    "all_c = forecast.Origin.unique().tolist() +  forecast.Destination.unique().tolist() # Not every hubs in the hub list is used\n",
    "all_c = list( dict.fromkeys(all_c) )  # Remove duplicate\n",
    "\n",
    "for x in used_c:\n",
    "    try:\n",
    "        all_c.remove(x)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "for c in all_c:\n",
    "    forecast[\"Origin\"].replace(c, np.nan, inplace = True)\n",
    "    forecast[\"Destination\"].replace(c, np.nan, inplace = True)\n",
    "forecast.dropna(how = \"any\", inplace = True)\n",
    "\n",
    "\n",
    "# Set up the threshold for the demands\n",
    "minimum_demands = 2000\n",
    "maximum_demands = 10000\n",
    "forecast[\"Target\"] = forecast.apply(lambda row: row.Average if row.Average >= minimum_demands else 0, axis = 1)\n",
    "\n",
    "forecast[\"Target\"] = forecast.apply(lambda row: row.Target if row.Target <= maximum_demands else 0, axis = 1)\n",
    "\n",
    "\n",
    "forecast = forecast[forecast[\"Target\"] > 0]\n",
    "country_set = list(zip(forecast[\"Origin\"].to_list(), forecast[\"Destination\"].to_list()))\n",
    "\n",
    "origin_list = list(forecast[\"Origin\"].unique())\n",
    "dst_list =  list(forecast[\"Destination\"].unique())\n",
    "\n",
    "country_with_forecast = forecast.Origin.unique().tolist() +  forecast.Destination.unique().tolist()\n",
    "country_with_forecast = list( dict.fromkeys(country_with_forecast))  # Remove Dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Set\n",
    "## 1. Hubs in each Country (L) & All Hubs (H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_hubs = masterfile.From.unique().tolist() +  masterfile.To.unique().tolist() # Not every hubs in the hub list is used\n",
    "used_hubs = list( dict.fromkeys(used_hubs) )  # Remove duplicate\n",
    "\n",
    "hub_list_used = hub_list.set_index(\"Ref_City\")\n",
    "hub_list_used = hub_list_used.loc[hub_list_used.index.isin(used_hubs), :]\n",
    "hub_list_used.reset_index(inplace = True)\n",
    "\n",
    "#hub_list_used[\"Country\"] = hub_list_used.apply(lambda row: row[\"Ref_City\"].split(\"-\")[-1], axis = 1) # To fill NA in country\n",
    "\n",
    "L = {}\n",
    "for country in country_with_forecast:  # hub_list_used.Country.unique():\n",
    "    hub_collect = hub_list_used[hub_list_used.loc[:, \"Country\"] == country][\"Ref_City\"].tolist()\n",
    "    L[country] = hub_collect\n",
    "\n",
    "    #for row in hub_list_used.index:\n",
    "\n",
    "    #L[hub_list_used.loc[row, \"Country\"]].append(hub_list_used.loc[row, \"Ref_City\"])\n",
    "H = hub_list_used.Ref_City.unique().tolist() # All hubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. European Countries (E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = country_with_forecast # from the \"forecast\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Truck Types (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "truck_cap = pd.read_csv(\"Database/TruckVSCap.csv\")\n",
    "T = truck_cap[\"Truck Type\"].tolist()\n",
    "T.remove(\"Swap Body\") # To simplify the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define subset for the later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tuplelist for the assign of variables\n",
    "\n",
    "mjk = tuplelist([(m,j,k) for m, k in country_set for j in country_with_forecast if (m != j) & (j != k)])\n",
    "mk = tuplelist([(m,k) for m, k in country_set])\n",
    "\n",
    "mj_k = [(m, j) for m in origin_list for j in country_with_forecast if (m, j) not in mk if m != j]   # m connects to j exlcudes k (transit countries)\n",
    "mj_k = list( dict.fromkeys(mj_k) )\n",
    "\n",
    "#j_mk = [(m, k) for m in country_with_forecast for k in dst_list if (m not in origin_list) & (m != k)]   # m connects to j exlcudes k (transit countries)\n",
    "j_mk = [(j, k)  for j in country_with_forecast for k in dst_list if (j,k) not in mk if k != j]  \n",
    "#j_mk = [(j, k) for m, j, k in mjk if (j,k) not in mk]   # j excludes m (transit countries), connects to k\n",
    "j_mk = list( dict.fromkeys(j_mk) )\n",
    "\n",
    "mk_all = j_mk + mj_k + mk\n",
    "mk_all = list( dict.fromkeys(mk_all) )\n",
    "\n",
    "pq = tuplelist([(p,q) for m,k in mk for p in L[m] for q in L[k]])\n",
    "piq = tuplelist([(p,i,q) for (m,j,k) in mjk for p in L[m] for i in L[j] for q in L[k]])\n",
    "pq_all = tuplelist((p, q) for m,k in mk_all for p in L[m] for q in L[k])\n",
    "pqt = tuplelist([(p,q,t) for p,q in pq_all for t in T])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all the parameters\n",
    "\n",
    "## 1. Cost: \n",
    "Transportation Cost between hub p ∈ H and hub q ∈ H using truck t ∈ T (Euro/ kg)\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_file = pd.read_csv(\"Database/Costs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor p, q in pq:\\n    cost[(p, q, \"Co-loading-Extra\")] = cost[(p, q, \"Van\")]*10\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = {}\n",
    "for row in cost_file.index:\n",
    "    cost_key = (cost_file[\"From\"][row], cost_file[\"To\"][row], cost_file[\"Truck type\"][row])\n",
    "    cost[cost_key] = cost_file[\"Cost/kg\"][row]\n",
    "    \n",
    "cl_distance = 1000\n",
    "\n",
    "if \"Co-loading\" in T:\n",
    "    for p, q in pq_all:\n",
    "        cost[(p, q, \"Co-loading\")] = max([cost[p_s, q_s, t] for p_s, q_s, t in pqt.select(p, q, \"*\") if t != \"Co-loading\"])*2 if cost[(p, q, \"Van\")] < ((0.6*cl_distance+5)/2250) else 99\n",
    "        # (0.6*500+5)/2250 use distance as a filter, over 500 km, the Co-loading opportunities are less\n",
    "'''\n",
    "for p, q in pq:\n",
    "    cost[(p, q, \"Co-loading-Extra\")] = cost[(p, q, \"Van\")]*10\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Forecast volume: Z\n",
    "Average forecasted parcel volume from country m ∈ E to country j ∈ E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = {}\n",
    "\n",
    "\n",
    "for row in forecast.index:\n",
    "    key = (forecast[\"Origin\"][row], forecast[\"Destination\"][row])\n",
    "    Z[key] = int(round(forecast[\"Target\"][row])) # Can only be interger\n",
    "\n",
    "# Some missing connection in the forecast\n",
    "for conn in mk:\n",
    "    if conn not in Z.keys():\n",
    "        Z[conn] = 0\n",
    "        print(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Current Freqency (F_)\n",
    "the frequency of truck t from hub to hub q in the current network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfreq_truck = pd.read_excel(\"Database/Result_Freq.xlsx\", sheet_name = 0)\\nfreq_truck.replace(\"Ryton Gateway\", \"Ryton\", inplace = True)\\nfreq_truck[\"From\"] = freq_truck.apply(lambda row: name_transform(row[\"Org. GTW\"]), axis = 1)\\nfreq_truck[\"To\"] = freq_truck.apply(lambda row: name_transform(row[\"Dst. GTW\"]), axis = 1)\\nfreq_truck.loc[:, :].to_csv(\"Database/current_network.csv\")\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following code transform the excel files to csv file in specific format\n",
    "'''\n",
    "freq_truck = pd.read_excel(\"Database/Result_Freq.xlsx\", sheet_name = 0)\n",
    "freq_truck.replace(\"Ryton Gateway\", \"Ryton\", inplace = True)\n",
    "freq_truck[\"From\"] = freq_truck.apply(lambda row: name_transform(row[\"Org. GTW\"]), axis = 1)\n",
    "freq_truck[\"To\"] = freq_truck.apply(lambda row: name_transform(row[\"Dst. GTW\"]), axis = 1)\n",
    "freq_truck.loc[:, :].to_csv(\"Database/current_network.csv\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_current = pd.read_csv(\"Database/current_network.csv\")\n",
    "# The following section work as a formatting part. To avoid different naming issues\n",
    "freq_current.replace(\"trailer\", \"Trailer\", inplace = True)\n",
    "freq_current.replace(\"2 swap bodies\", \"2 Swap Bodies\", inplace = True)\n",
    "freq_current.replace(\"van\", \"Van\", inplace = True)\n",
    "freq_current.replace(\"1 swap body\", \"Swap Body\", inplace = True)\n",
    "freq_current.replace(\"SEMI TRAILER\", \"Swap Body\", inplace = True)\n",
    "freq_current.replace(\"Cargo 50 m3\", \"Swap Body\", inplace = True)\n",
    "freq_current.replace(\"Sea Container\", \"2 Swap Bodies\", inplace = True)\n",
    "freq_current.replace(\"Van 15 m3\", \"Van\", inplace = True)\n",
    "freq_current.replace(\"Van 22m3\", \"Van\", inplace = True)\n",
    "freq_current.replace(\"4 swap bodies\", \"2 Swap Bodies\", inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_ = {}\n",
    "for row in freq_current.index:\n",
    "    key = (freq_current.loc[row, \"From\"], freq_current.loc[row, \"To\"], freq_current.loc[row, \"Truck type\"])\n",
    "    value = freq_current.loc[row, \"Frequency\"]\n",
    "    \n",
    "    F_[key] = value\n",
    "    \n",
    "for target in pqt:\n",
    "    if target not in F_.keys():\n",
    "        F_[target] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Travel time (TT)\n",
    "Total transportation time from hub p ∈ H to q ∈ H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_file = pd.read_csv(\"Database/travel time.csv\")\n",
    "TT = {}\n",
    "for row in tt_file.index:\n",
    "    key = (tt_file.loc[row, \"From\"], tt_file.loc[row, \"To\"])\n",
    "    value = tt_file.loc[row, \"est_tt\"]\n",
    "    \n",
    "    TT[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hub Open & Cut-off time\n",
    "- Op = Hub opened time for hub p ∈ H\n",
    "- COp  = Hub cut off time for hub p ∈ H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_time(target):\n",
    "    try: \n",
    "        return int(target.split(\":\")[0]) + int(target.split(\":\")[1])/60 \n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhub_info = pd.read_csv(\"Database/Hub Cutoff and Open Time.csv\")\\nhub_info[\"Hub\"] = hub_info.apply(lambda row: name_transform(row[\"Gateways\"]), axis = 1)\\nhub_info[\"Cut-off\"] = hub_info.apply(lambda row: transform_time(row[\"Cut-Off\"]), axis = 1)\\nhub_info[\"Open\"] = hub_info.apply(lambda row: transform_time(row[\"Hub-Opening-Time\"]), axis = 1)\\nhub_info.to_csv(\"Database/hub_info.csv\")\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "hub_info = pd.read_csv(\"Database/Hub Cutoff and Open Time.csv\")\n",
    "hub_info[\"Hub\"] = hub_info.apply(lambda row: name_transform(row[\"Gateways\"]), axis = 1)\n",
    "hub_info[\"Cut-off\"] = hub_info.apply(lambda row: transform_time(row[\"Cut-Off\"]), axis = 1)\n",
    "hub_info[\"Open\"] = hub_info.apply(lambda row: transform_time(row[\"Hub-Opening-Time\"]), axis = 1)\n",
    "hub_info.to_csv(\"Database/hub_info.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hub_info = pd.read_csv(\"Database/hub_info.csv\")\n",
    "merged_hub_info = hub_list_used.merge(hub_info[[\"Hub\", \"Open\", \"Cut-off\"]], left_on = \"Ref_City\", right_on = \"Hub\", how = \"left\")\n",
    "\n",
    "merged_hub_info[\"Open\"].fillna(merged_hub_info[\"Open\"].mode().values[0], inplace = True)\n",
    "merged_hub_info[\"Cut-off\"].fillna(merged_hub_info[\"Cut-off\"].mode().values[0], inplace = True)\n",
    "\n",
    "O = {} # Open time\n",
    "for row in merged_hub_info.index:\n",
    "    key = merged_hub_info.loc[row, \"Ref_City\"]\n",
    "    value = merged_hub_info.loc[row, \"Open\"]\n",
    "    O[key] = value\n",
    "\n",
    "CO = {} # Cut-off time\n",
    "for row in merged_hub_info.index:\n",
    "    key = merged_hub_info.loc[row, \"Ref_City\"]\n",
    "    value = merged_hub_info.loc[row, \"Cut-off\"]\n",
    "    CO[key] =  value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Truck Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = {}\n",
    "for row in truck_cap.index:\n",
    "    C[truck_cap.loc[row, \"Truck Type\"]] = truck_cap.loc[row, \"Capacity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file /Users/yi/gurobi.lic\n",
      "Academic license - for non-commercial use only\n"
     ]
    }
   ],
   "source": [
    "model = Model(\"DHL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the variables\n",
    "Decision variables:\n",
    "- xpq = 1 if the transportation from hub p ∈ H to hub q ∈ H is direct, else 0  \n",
    "- x’piq = 1 if the transportation from hub p ∈ H to hub q ∈ H has to go through i ∈ H, else 0\n",
    "- Xmk = 1 if the transportation from country m ∈ E to county k ∈ E is direct, else 0\n",
    "- X’mjk = 1 if the transportation from country m ∈ E  to county k ∈ E  has to go through country j ∈ E , else 0\n",
    "- Vpq = route capacity from hub p ∈ H to hub q ∈ H\n",
    "- Fpqt = recommended frequency of truck t ∈ T from hub p ∈ H to hub q ∈ H\n",
    "- Spq = start time of truck from hub p ∈ H to hub q ∈ H,\n",
    "- Npq = Night needed from hub p ∈ H to hub q ∈ H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.addVars(pq , vtype=GRB.BINARY, name='xpq')  # Direct from hub to hub\n",
    "\n",
    "x_ = model.addVars(piq, vtype = GRB.BINARY, name = 'x_piq')  # Indirect from hub to hub\n",
    "\n",
    "X = model.addVars(mk , vtype=GRB.BINARY, name='Xmk')       # Direct from country to country\n",
    "\n",
    "X_ = model.addVars(mjk,  vtype = GRB.BINARY, name = 'X_mjk') # Indirect from country to country\n",
    "\n",
    "V = model.addVars(pq_all , vtype=GRB.INTEGER, lb=0 ,name='Vpq')   # Route capacity\n",
    "\n",
    "F=model.addVars(pqt , vtype=GRB.INTEGER, lb=0, name='Fpqt') # Recommended Frequency\n",
    "\n",
    "S=model.addVars(pq_all , vtype=GRB.CONTINUOUS, name='Spq')         # Start time from hub p\n",
    "\n",
    "N=model.addVars(pq_all , vtype=GRB.INTEGER, name='Npq')         # Night Needed from hub p to hub q\n",
    "\n",
    "CL = model.addVars(pq_all, vtype = GRB.INTEGER, lb = 0, name = \"CLpq\") # Co-loading (in) between p and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "attri_dict = {\"hub_direct\": x, \"hub_indirect\" : x_, \"country_direct\" : X, \"country_indirect\" : X_,\n",
    "              \"route_cap\": V, \"freq\" : F, \"start\" : S, \"night\" : N, \"Co-loading\":CL}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"NL\", \"AT\") in mj_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update()\n",
    "\n",
    "# Minimize the travel time for each route\n",
    "model.setObjective(quicksum(x[p, q] * TT[p, q] for p, q in pq) +\n",
    "                   quicksum(x_[p, i ,q] * (TT[p, i] + 9 + TT[i, q])for p, i, q in piq) # Consider the transit time in the hubs\n",
    "                                                                                       # Taking 9 as an example\n",
    "                   ,  GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gurobi.Constr *Awaiting Model Update*>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "### Constraints\n",
    "## Direct or Indirect Transportation\n",
    "\n",
    "model.addConstrs(((quicksum(X_[m,j,k] for j in E if (j != m) & (j != k)) == \n",
    "                   (1 - X[m,k])) for m, k in mk),\n",
    "                 \"Transportation can be direct or Indirect\")\n",
    "\n",
    "\n",
    "## Linking Countries and Hubs\n",
    "\n",
    "model.addConstrs(((quicksum(x[p,q] for p in L[m] for q in L[k]) == \n",
    "                  X[m,k]) for m, k in mk), \"Linking_pq\")  ## We can't use E_mjk here\n",
    "model.addConstrs(((quicksum(x_[p,i,q] for p in L[m] for i in L[j] for q in L[k]) ==\n",
    "                 X_[m,j,k]) for m,j,k in mjk), \"Linking_piq\")\n",
    "\n",
    "## Truck Capacity:\n",
    "\n",
    "# V = monthly demand of the route\n",
    "# For the countries of p, q are in mk\n",
    "model.addConstrs(((V[p,q] ==  \n",
    "                 quicksum(x_[p,q,i] * Z[m,j] for m, k, j in mjk.select(m, k, \"*\") for i in L[j]) +\n",
    "                 quicksum(x_[i,p,q] * Z[j,k] for j, m, k in mjk.select(\"*\", m, k) for i in L[j]) + \n",
    "                 x[p,q] * Z[m,k])\n",
    "                 for m, k in mk for p in L[m] for q in L[k]), \"Truck Capacity\")\n",
    "\n",
    "# For the countries of p are in the origin, q are not in the destination:\n",
    "model.addConstrs((V[p,q] ==  \n",
    "                 quicksum(x_[p,q,i] * Z[m,j] for m, k, j in mjk.select(m, k, \"*\") for i in L[j])\n",
    "                 for m, k in mj_k for p in L[m] for q in L[k] if (m,k) not in j_mk), \"Truck Capacity\")\n",
    "                 \n",
    "# For the countries of p are not in the origin, q are in the destination:           \n",
    "model.addConstrs((V[p,q] ==  \n",
    "                 quicksum(x_[i,p,q] * Z[j,k] for j, m, k in mjk.select(\"*\", m, k) for i in L[j]) \n",
    "                 for m, k in j_mk for p in L[m] for q in L[k] if (m,k) not in mj_k), \"Truck Capacity\")\n",
    "\n",
    "# For the countries of p and q are not in mk, but in j_mk and mj_k in the same time\n",
    "model.addConstrs((V[p,q] ==  \n",
    "                 quicksum(x_[p,q,i] * Z[m,j] for m, k, j in mjk.select(m, k, \"*\") for i in L[j]) +\n",
    "                 quicksum(x_[i,p,q] * Z[j,k] for j, m, k in mjk.select(\"*\", m, k) for i in L[j])\n",
    "                 for m, k in j_mk for p in L[m] for q in L[k] if (m,k) in mj_k), \"Truck Capacity 4\")\n",
    "\n",
    "\n",
    "## Truck type and Frequency of trucks\n",
    "# transforming the weekly frequency to monthly by multiplying 4\n",
    "model.addConstrs(((V[p,q] + CL[p, q]*4 <=   # Updated\n",
    "                 quicksum(F[p,q,t] * C[t] * 4 for t in T) )\n",
    "                 for m, k in mk_all for q in L[k] for p in L[m]),\n",
    "                 \"Truck Type and Frequency\"\n",
    "                )\n",
    "\n",
    "# Co-loading out constraints\n",
    "# model.addConstrs((F[p,q,\"Co-loading\"] <= 2000 for p,q in pq_all), \"Coloading out constraints\") ## Removed after discussion on 6/22\n",
    "\n",
    "# Co-loading in constraints\n",
    "model.addConstrs((CL[p,q] <= 2000 for p,q in pq_all), \"Coloading in constraints\")\n",
    "model.addConstrs((CL[p,q] <= quicksum(F[p,q,t]*C[t] for t in T)*0.3 for p, q in pq_all), \"Coloading in constraints 2\")\n",
    "\n",
    "BigM = 9999\n",
    "model.addConstrs((S[p,q] + TT[p,q] - N[p,q] * 24  <=  \n",
    "                 CO[q] + \n",
    "                 BigM * (\n",
    "                     1 - (x[p, q] + \n",
    "                          quicksum(x_[p, q, i] for m, k, j in mjk.select(m, k, \"*\") for i in L[j]) + \n",
    "                          quicksum(x_[i, p, q] for j, m, k in mjk.select(\"*\", m, k) for i in L[j])\n",
    "                 ) ) for m,k in mk for q in L[k] for p in L[m]), \"Hub Cut Off Time\")\n",
    "\n",
    "\n",
    "BigMM = 9000\n",
    "\n",
    "model.addConstrs((S[p,q] + TT[p,q] - N[p,q] * 24  >=  \n",
    "                 O[q] + \n",
    "                 BigMM * (\n",
    "                     1 - (x[p, q] + \n",
    "                          quicksum(x_[p, q, i] for m, k, j in mjk.select(m, k, \"*\") for i in L[j]) + \n",
    "                          quicksum(x_[i, p, q] for j, m, k in mjk.select(\"*\", m, k) for i in L[j])\n",
    "                 ) ) for m,k in mk for q in L[k] for p in L[m]), \"Hub Open Time\")\n",
    "\n",
    "\n",
    "# Assumption: all the excessive spaces could be loaded with co-loading opportunities in the current network\n",
    "# Assumption: In the new network, all the co-loading oppottunities doesn't exist\n",
    "\n",
    "\n",
    "Cost_bound = 1.05\n",
    "Current_full = 0.8\n",
    "\n",
    "\n",
    "'''\n",
    "# The tighten model (loose a bit)\n",
    "model.addConstr((quicksum(F[p,q,t] * cost[p,q,t] * C[t] for p, q, t in pqt) *\n",
    "                 quicksum(F_[p,q,t] * C[t] for p, q, t in pqt) <= \n",
    "                 (quicksum(F_[p,q,t] * cost[p,q,t] * C[t] for p, q, t in pqt) *\n",
    "                 (quicksum(Z[m,k] for m, k in mk)/4 + quicksum(CL[p,q] for p,q in pq)) * Cost_bound))\n",
    "                 , \"Cost Constraint\")\n",
    "'''\n",
    "\n",
    "current_cost = sum(F_[p,q,t] * C[t] * cost[p,q,t] for p, q, t in pqt) / sum(F_[p,q,t] * C[t] for p,q,t in pqt)\n",
    "\n",
    "model.addConstr((quicksum(F[p,q,t] * cost[p,q,t] * C[t] for p, q, t in pqt) <= \n",
    "                 (current_cost * (quicksum(V[p,q] for p, q in pq_all) / 4 + quicksum(CL[p,q] for p,q in pq))) * Cost_bound / Current_full), \"Cost Constraint\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics for model DHL :\n",
      "  Linear constraint matrix    : 18827 Constrs, 60002 Vars, 167144 NZs\n",
      "  Variable types              : 4276 Continuous, 55726 Integer (25794 Binary)\n",
      "  Matrix coefficient range    : [ 0.0247484, 33524 ]\n",
      "  Objective coefficient range : [ 4.41, 197.2 ]\n",
      "  Variable bound range        : [ 1, 1 ]\n",
      "  RHS coefficient range       : [ 1, 10012.6 ]\n"
     ]
    }
   ],
   "source": [
    "model.update()\n",
    "model.printStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded solution information\n",
      "Changed value of parameter TimeLimit to 3600.0\n",
      "   Prev: inf  Min: 0.0  Max: inf  Default: inf\n",
      "Changed value of parameter Heuristics to 0.5\n",
      "   Prev: 0.05  Min: 0.0  Max: 1.0  Default: 0.05\n",
      "Changed value of parameter MIPFocus to 3\n",
      "   Prev: 0  Min: 0  Max: 3  Default: 0\n",
      "Changed value of parameter TuneCriterion to 2\n",
      "   Prev: -1  Min: -1  Max: 3  Default: -1\n",
      "Parameter TuneTrials unchanged\n",
      "   Value: 3  Min: 1  Max: 2000000000  Default: 3\n",
      "Changed value of parameter Seed to 3\n",
      "   Prev: 0  Min: 0  Max: 2000000000  Default: 0\n",
      "Changed value of parameter TuneTimeLimit to 1200.0\n",
      "   Prev: -1.0  Min: -1.0  Max: inf  Default: -1.0\n",
      "\n",
      "Solving model using baseline parameter set with TimeLimit=3600s\n",
      "\n",
      "Solving with random seed #1 ...\n",
      "Optimize a model with 18827 rows, 60002 columns and 167144 nonzeros\n",
      "Model fingerprint: 0x7d84f13b\n",
      "Variable types: 4276 continuous, 55726 integer (25794 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 3e+04]\n",
      "  Objective range  [4e+00, 2e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+04]\n",
      "Presolve removed 8577 rows and 16644 columns\n",
      "Presolve time: 1.12s\n",
      "Presolved: 10250 rows, 43358 columns, 122995 nonzeros\n",
      "Variable types: 0 continuous, 43358 integer (29221 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "Presolve removed 619 rows and 1038 columns\n",
      "Presolved: 9631 rows, 42320 columns, 120919 nonzeros\n",
      "\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with primal simplex\n",
      "\n",
      "Root relaxation: objective 1.046190e+03, 17429 iterations, 1.28 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1046.18986    0  113          - 1046.18986      -     -    3s\n"
     ]
    }
   ],
   "source": [
    "model.reset()\n",
    "\n",
    "timeLimit = 3600*1 # In second\n",
    "\n",
    "model.Params.TimeLimit = timeLimit - model.getAttr(GRB.Attr.Runtime)\n",
    "\n",
    "model.Params.Heuristics = 0.5\n",
    "\n",
    "model.Params.MIPFocus=3\n",
    "\n",
    "model.Params.TuneCriterion = 2\n",
    "\n",
    "model.Params.TuneTrials = 3\n",
    "\n",
    "model.Params.Seed = 3\n",
    "\n",
    "model.Params.TuneTimeLimit = timeLimit/3\n",
    "\n",
    "model.tune()\n",
    "\n",
    "# model.feasRelaxS(1, False, False, True)\n",
    "\n",
    "model.optimize()\n",
    "\n",
    "\n",
    "'''\n",
    "if model.tuneResultCount > 0:\n",
    "\n",
    "    # Load the best tuned parameters into the model\n",
    "    model.getTuneResult(0)\n",
    "\n",
    "    # Write tuned parameters to a file\n",
    "    model.write('tune.prm')\n",
    "\n",
    "    # Solve the model using the tuned parameters\n",
    "    model.optimize()\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_to_df(Var, col_name = None):  # Here you could input the variable\n",
    "    solution = model.getAttr('x_', Var)\n",
    "    num_col = len(solution.keys()[0])\n",
    "    collect = []\n",
    "    for row in range(0, len(solution)):\n",
    "        new_row = []\n",
    "        for col in range(0, num_col):\n",
    "            new_row.append(solution.keys()[row][col])\n",
    "        new_row.append(solution[solution.keys()[row]])\n",
    "    \n",
    "        collect.append(new_row)\n",
    "    return pd.DataFrame(collect, columns = col_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hub_Indirect = turn_to_df(x_, [\"Ori_Hub\", \"Transit_Hub\",\"Dest_Hub\", \"Taken\"])\n",
    "Hub_Indirect[Hub_Indirect.Taken > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country_Direct = turn_to_df(X, [\"Ori_Country\", \"Dest_Country\", \"Taken\"])\n",
    "Country_Indirect = turn_to_df(X_, [\"Ori_Country\", \"Transit_Country\",\"Dest_Country\", \"Taken\"])\n",
    "\n",
    "Hub_Direct = turn_to_df(x, [\"Ori_Hub\", \"Dest_Hub\", \"Taken\"])\n",
    "Hub_Indirect = turn_to_df(x_, [\"Ori_Hub\", \"Transit_Hub\",\"Dest_Hub\", \"Taken\"])\n",
    "\n",
    "Route_Cap = turn_to_df(V, [\"Ori_Hub\", \"Dest_Hub\", \"Taken\"])\n",
    "Freq = turn_to_df(F, [\"Ori_Hub\", \"Dest_Hub\",\"Truck Type\", \"Taken\"])\n",
    "Start = turn_to_df(S, [\"Ori_Hub\", \"Dest_Hub\", \"Time\"])\n",
    "Night = turn_to_df(N, [\"Ori_Hub\", \"Dest_Hub\", \"Nights\"])\n",
    "Co_load = turn_to_df(CL, [\"Ori_Hub\", \"Dest_Hub\", \"Amount\"])\n",
    "CL_sol =  model.getAttr('x_', CL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in attri_dict.keys():\n",
    "    df_output = turn_to_df(attri_dict[key])\n",
    "    df_output.to_csv(f\"Output/{key}_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = Country_Indirect.Taken.sum()\n",
    "d = Country_Direct.Taken.sum()\n",
    "\n",
    "print(f\"{ind} indriect routes and {d} direct route, total: {len(Z)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_result = model.getAttr('x', F)\n",
    "demand_filled = model.getAttr('x', V)\n",
    "print(\"Cost by Route Cap.:\", round(sum(freq_result[p,q,t] * C[t] * cost[p,q,t] for p, q, t in pqt) / (sum(demand_filled[p,q] for p, q in pq_all)/4), 2))\n",
    "print(\"Cost by Capacity.:\", sum(freq_result[p,q,t] * C[t] * cost[p,q,t] for p, q,t in pqt) / (sum(freq_result[p,q,t] * C[t] for p, q,t in pqt)))\n",
    "print(\"Cost by Demands.:\", sum(freq_result[p,q,t] * C[t] * cost[p,q,t] for p, q,t in pqt) / (sum(Z[m, k] for m, k in mk)/4))\n",
    "print(\"Cost by Demands + Co-load:\", sum(freq_result[p,q,t] * C[t] * cost[p,q,t] for p, q, t in pqt) / (sum(Z[m, k] for m, k in mk)/4 + sum(CL_sol[p, q] for p, q in pq_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(F_[p,q,t] * C[t] * cost[p,q,t] for p, q, t in pqt) / sum(F_[p,q,t] * C[t] for p,q,t in pqt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Freq_result = Freq[Freq.Taken > 0]\n",
    "Freq_result.groupby(\"Truck Type\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Freq_result = Freq[Freq.Taken > 0]\n",
    "Freq_result[\"agg\"] = Freq_result[\"Ori_Hub\"] + Freq_result[\"Dest_Hub\"]\n",
    "print(Freq_result.groupby(\"Truck Type\").count()) # Truck type count per routes\n",
    "\n",
    "Freq_result[\"Capacity\"] = Freq_result.apply(lambda row: C[row[\"Truck Type\"]] * row[\"Taken\"] * 4, axis = 1)\n",
    "capacity_from_freq = Freq_result.groupby([\"agg\"]).sum()\n",
    "\n",
    "\n",
    "# Indirect Route Overview\n",
    "\n",
    "Hub_Indirect_T = Hub_Indirect[Hub_Indirect.Taken > 0]\n",
    "Hub_Indirect_T[\"First\"] = Hub_Indirect_T[\"Ori_Hub\"] + Hub_Indirect_T[\"Transit_Hub\"]\n",
    "Hub_Indirect_T[\"Second\"] = Hub_Indirect_T[\"Transit_Hub\"] + Hub_Indirect_T[\"Dest_Hub\"]\n",
    "\n",
    "Hub_merge = Hub_Indirect_T.merge(capacity_from_freq.loc[:, \"Capacity\"], left_on = \"First\", right_on = \"agg\", how = \"right\")\n",
    "Hub_merge = Hub_merge.merge(capacity_from_freq.loc[:, \"Capacity\"], left_on = \"Second\", right_on = \"agg\", how = \"right\")\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "Hub_merge.dropna() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Co_load[Co_load[\"Amount\"] > 0]\n",
    "capacity_from_freq\n",
    "Hub_Indirect_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if some routes exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\"FR\",\"ES\") in mk_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "solution = model.getAttr('x_', X_)\n",
    "print(solution[(\"HU\", \"AT\",\"BE\")])\n",
    "\n",
    "solution_dir = model.getAttr('x_', X)\n",
    "solution_dir[(\"AT\",\"BE\")]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Freq[\"Ori_C\"] = Freq.apply(lambda row: row.Ori_Hub.rsplit(\"-\")[-1], axis = 1)\n",
    "Freq[\"Dest_C\"] = Freq.apply(lambda row: row.Dest_Hub.rsplit(\"-\")[-1], axis = 1)\n",
    "Freq[Freq.Taken > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Freq.loc[(Freq[\"Ori_C\"] == \"BE\") & (Freq[\"Dest_C\"] == \"DE\"), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the relationship between Route Capacity and Demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Route_Cap[\"Ori_C\"] = Route_Cap.apply(lambda row: row.Ori_Hub.rsplit(\"-\")[-1], axis = 1)\n",
    "Route_Cap[\"Dest_C\"] = Route_Cap.apply(lambda row: row.Dest_Hub.rsplit(\"-\")[-1], axis = 1)\n",
    "Route_Cap[\"Demands\"] = Route_Cap.apply(lambda row: Z[row.Ori_C, row.Dest_C] if (row.Ori_C, row.Dest_C) in Z.keys() else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route_Cap.loc[(Route_Cap[\"Ori_C\"] == \"DE\") & (Route_Cap[\"Dest_C\"] == \"FL\"), :]\n",
    "Route_Cap[Route_Cap.Taken > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Route_Cap.loc[(Route_Cap[\"Ori_C\"] == \"BE\") & (Route_Cap[\"Dest_C\"] == \"NL\"), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z[\"BE\", \"AT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"NL\", \"AT\") in mk_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
